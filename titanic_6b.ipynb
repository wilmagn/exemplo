{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas --> numpy\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher vazios\n",
    "class Preencher_vazios(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, values):\n",
    "        self.values = values\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # values = {'Age': train['Age'].median(),'Cabin':'C1000','Embarked':'X'}\n",
    "        X.fillna(value=self.values, inplace = True)        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma valores (A,cam, ve) em numeros(0,1,2,..) - aplicavel em todo o DataFrame \n",
    "class Transformar_categoricos(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.apply(lambda x: pd.factorize(x)[0])        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_um(matriz):\n",
    "    matriz[np.where(matriz<=0.50)] = 0\n",
    "    matriz[np.where(matriz>0.50)] = 1\n",
    "    return matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.ylim([0, 1])\n",
    "    #plt.xlim([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test_set = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.005007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived    Pclass       Age     SibSp     Parch  \\\n",
       "PassengerId     1.000000 -0.005007 -0.035144  0.036847 -0.057527 -0.001652   \n",
       "Survived       -0.005007  1.000000 -0.338481 -0.077221 -0.035322  0.081629   \n",
       "Pclass         -0.035144 -0.338481  1.000000 -0.369226  0.083081  0.018443   \n",
       "Age             0.036847 -0.077221 -0.369226  1.000000 -0.308247 -0.189119   \n",
       "SibSp          -0.057527 -0.035322  0.083081 -0.308247  1.000000  0.414838   \n",
       "Parch          -0.001652  0.081629  0.018443 -0.189119  0.414838  1.000000   \n",
       "Fare            0.012658  0.257307 -0.549500  0.096067  0.159651  0.216225   \n",
       "\n",
       "                 Fare  \n",
       "PassengerId  0.012658  \n",
       "Survived     0.257307  \n",
       "Pclass      -0.549500  \n",
       "Age          0.096067  \n",
       "SibSp        0.159651  \n",
       "Parch        0.216225  \n",
       "Fare         1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026751</td>\n",
       "      <td>-0.034102</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.043080</td>\n",
       "      <td>0.008211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.026751</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.492143</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.018721</td>\n",
       "      <td>-0.577147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.034102</td>\n",
       "      <td>-0.492143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091587</td>\n",
       "      <td>-0.061249</td>\n",
       "      <td>0.337932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>-0.091587</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.306895</td>\n",
       "      <td>0.171539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.043080</td>\n",
       "      <td>0.018721</td>\n",
       "      <td>-0.061249</td>\n",
       "      <td>0.306895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.230046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.008211</td>\n",
       "      <td>-0.577147</td>\n",
       "      <td>0.337932</td>\n",
       "      <td>0.171539</td>\n",
       "      <td>0.230046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId    Pclass       Age     SibSp     Parch      Fare\n",
       "PassengerId     1.000000 -0.026751 -0.034102  0.003818  0.043080  0.008211\n",
       "Pclass         -0.026751  1.000000 -0.492143  0.001087  0.018721 -0.577147\n",
       "Age            -0.034102 -0.492143  1.000000 -0.091587 -0.061249  0.337932\n",
       "SibSp           0.003818  0.001087 -0.091587  1.000000  0.306895  0.171539\n",
       "Parch           0.043080  0.018721 -0.061249  0.306895  1.000000  0.230046\n",
       "Fare            0.008211 -0.577147  0.337932  0.171539  0.230046  1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Juntar_tratamento(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, train, test_set):\n",
    "        return self\n",
    "\n",
    "    def transform(self, train, test_set, y=None):\n",
    "        #Juntar para tratamento\n",
    "        train = train.set_index('PassengerId')\n",
    "        test_set = test_set.set_index('PassengerId')\n",
    "\n",
    "        lista_index_train = train.index.tolist()\n",
    "        lista_index_test_set = test_set.index.tolist()\n",
    "\n",
    "        todos = pd.concat([train,test_set],axis=0)\n",
    "\n",
    "        test_set = todos.loc[lista_index_test_set].reset_index()\n",
    "        todos = todos.reset_index()\n",
    "\n",
    "        # Separar a coluna dos sobreviventes\n",
    "        train_label = train['Survived']\n",
    "        train_set = todos.loc[lista_index_train].drop('Survived', axis=1)\n",
    "        \n",
    "        return todos, train_label \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s = Juntar_tratamento()\n",
    "todos = s.transform(train,test_set)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pronomes_tratamento(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, todos, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, todos):\n",
    "        # Categorizar pronomes de tratamento\n",
    "        l = list()\n",
    "        todos['Name_3'] = \"\"\n",
    "        for index, row in todos.iterrows():   \n",
    "            try:\n",
    "                a = float(todos.iloc[index]['Age'])\n",
    "\n",
    "                if np.isnan(a):\n",
    "                    tipo = 'nan'   \n",
    "                elif not np.isnan(a):\n",
    "                    tipo = 'ok'\n",
    "            except:\n",
    "                tipo = 'nan'\n",
    "\n",
    "            jl = todos.iloc[index]['Name']\n",
    "            c = re.match('(.*?)[\\s]*[\\,][\\s]*', jl)\n",
    "            a = re.match('(.*?)[\\s]*[\\,][\\s]*Mr[\\.\\s].*', jl)\n",
    "            b = re.match('(.*?)[\\s]*[\\,][\\s]*Dr[\\.\\s].*', jl)\n",
    "\n",
    "            d = re.match('(.*?)[\\s]*[\\,][\\s]*Master[\\.\\s].*', jl)    \n",
    "\n",
    "            e = re.match('(.*?)[\\s]*[\\,][\\s]*Miss[\\.\\s].*', jl)\n",
    "            f = re.match('(.*?)[\\s]*[\\,][\\s]*Mrs[\\.\\s].*', jl)\n",
    "            g = re.match('(.*?)[\\s]*[\\,][\\s]*Ms[\\.\\s].*', jl)\n",
    "\n",
    "            h = re.match('(.*?)[\\s]*[\\,][\\s]Rev[\\.\\s].*', jl)\n",
    "\n",
    "            i = re.match('(.*?)[\\s]*[\\,][\\s]*Col[\\.\\s].*', jl)\n",
    "            j = re.match('(.*?)[\\s]*[\\,][\\s]*Major[\\.\\s].*', jl)\n",
    "\n",
    "            if   a: \n",
    "                l.append(0)\n",
    "            elif b:\n",
    "                l.append(0)\n",
    "            elif d:\n",
    "                l.append(0)\n",
    "            elif e:       \n",
    "                l.append(1)\n",
    "            elif f:       \n",
    "                l.append(2)\n",
    "            elif g:       \n",
    "                l.append(3)\n",
    "            elif h:       \n",
    "                l.append(0)\n",
    "            elif i:       \n",
    "                l.append(0)\n",
    "            elif j:       \n",
    "                l.append(0)\n",
    "            else:\n",
    "                l.append(4) \n",
    "\n",
    "            if c:\n",
    "                todos.at[index, 'Name_3'] = c.group(1) #coluna de sobrenomes\n",
    "\n",
    "         # Atribuir uma idade que esteja faltando - filtrar pro grupo   \n",
    "            if (a or b  or e or g or h or i or f) and (tipo == 'nan'):\n",
    "                todos.at[index, 'Age'] = 28.\n",
    "\n",
    "            elif (d) and (tipo == 'nan'):       \n",
    "                todos.at[index, 'Age'] = 4.\n",
    "\n",
    "            elif (tipo == 'nan'):\n",
    "                todos.at[index, 'Age'] = 28.\n",
    "\n",
    "        todos['Name_2'] = l\n",
    "        todos['Cabin_2']= todos['Cabin'].str.extract('(.).*', expand=False)\n",
    "        \n",
    "        return todos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s = Pronomes_tratamento()\n",
    "todos = s.transform(todos)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sobrevivente_familia(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, todos, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, todos):\n",
    "        # Cria uma nova coluna com a chance de sobreviver de acordo com a familia.\n",
    "        count = 0\n",
    "        nosurv = 0\n",
    "        surv = 0\n",
    "        s_ns = list()\n",
    "        s_ns_novo = list()\n",
    "        c_dict ={}\n",
    "        c_dict_baixo ={}\n",
    "        c_dict_baixo_2 = {}\n",
    "        c_dict_alto ={}\n",
    "        var = len(todos[0:891][todos[0:891]['Survived']==1])/len(todos[0:891])\n",
    "        todos['Name_4'] = ''\n",
    "        todos['numero_sobrevivente_familia'] =''\n",
    "        todos['numero_total_familia'] =''\n",
    "        todos['relacao_s_ns_familia'] = ''\n",
    "\n",
    "        #calcula o numero de sobrevivente de cada familia e cria uma coluna\n",
    "        for index, row in todos[0:891].iterrows():  \n",
    "            if todos[0:891].iloc[index]['Name_3'] not in c_dict.keys():\n",
    "                c_dict[todos[0:891].iloc[index]['Name_3']] = [0,0]\n",
    "\n",
    "            s_ns = c_dict[todos[0:891].iloc[index]['Name_3']]\n",
    "\n",
    "            if todos[0:891].iloc[index]['Survived'] == 0:            \n",
    "                s_ns_novo = [s_ns[0] + 1, s_ns[1]]\n",
    "            elif todos[0:891].iloc[index]['Survived'] == 1: \n",
    "                s_ns_novo = [s_ns[0], s_ns[1] + 1]\n",
    "\n",
    "            c_dict[todos.iloc[index]['Name_3']] = s_ns_novo  \n",
    "\n",
    "        for index, row in todos.iterrows():  \n",
    "            if todos.iloc[index]['Name_3'] in c_dict:\n",
    "                todos.at[index, 'numero_sobrevivente_familia'] =  c_dict[todos.iloc[index]['Name_3']][1] \n",
    "\n",
    "                todos.at[index, 'numero_total_familia'] =  sum(c_dict[todos.iloc[index]['Name_3']] ) \n",
    "\n",
    "                if todos.iloc[index]['numero_total_familia'] > 1:\n",
    "                    todos.at[index, 'relacao_s_ns_familia'] = todos.iloc[index]['numero_sobrevivente_familia']/todos.iloc[index]['numero_total_familia']\n",
    "                else:\n",
    "                    todos.at[index, 'relacao_s_ns_familia'] = var\n",
    "\n",
    "            if todos.iloc[index]['Name_3'] not in c_dict:\n",
    "                todos.at[index, 'numero_sobrevivente_familia'] =  0.\n",
    "\n",
    "                todos.at[index, 'numero_total_familia'] =  0.\n",
    "\n",
    "                todos.at[index, 'relacao_s_ns_familia'] = var\n",
    "\n",
    "            if todos.iloc[index]['relacao_s_ns_familia'] >= 0. and todos.iloc[index]['relacao_s_ns_familia'] < 0.25:\n",
    "                todos.at[index, 'relacao_s_ns_familia'] = 0.25\n",
    "            elif todos.iloc[index]['relacao_s_ns_familia'] >= 0.25 and todos.iloc[index]['relacao_s_ns_familia'] < 0.5:        \n",
    "                todos.at[index, 'relacao_s_ns_familia'] = 0.5\n",
    "            elif todos.iloc[index]['relacao_s_ns_familia'] >= 0.5 and todos.iloc[index]['relacao_s_ns_familia'] < 0.75:        \n",
    "                todos.at[index, 'relacao_s_ns_familia'] = 0.75      \n",
    "            elif todos.iloc[index]['relacao_s_ns_familia'] >= 0.75:       \n",
    "                todos.at[index, 'relacao_s_ns_familia'] = 1.0   \n",
    "\n",
    "        todos['Name_4'] =  todos['relacao_s_ns_familia']        \n",
    "        todos = todos.infer_objects()\n",
    "        return todos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s = Sobrevivente_familia()\n",
    "todos = s.transform(todos)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sobrevivente_cabine(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, todos, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, todos):\n",
    "        # Cria uma nova coluna com a chance de sobreviver de acordo com a cabine.\n",
    "        count = 0\n",
    "        nosurv = 0\n",
    "        surv = 0\n",
    "        s_ns = list()\n",
    "        s_ns_novo = list()\n",
    "        c_dict ={}\n",
    "        c_dict_baixo ={}\n",
    "        c_dict_baixo_2 = {}\n",
    "        c_dict_alto ={}\n",
    "        var = len(todos[0:891][todos[0:891]['Survived']==1])/len(todos[0:891])\n",
    "        todos['Cabin_3'] = \"\"\n",
    "        todos['numero_sobrevivente_cabine'] =''\n",
    "        todos['numero_total_cabine'] =''\n",
    "        todos['relacao_s_ns_cabine'] = ''\n",
    "\n",
    "        #calcula o numero de sobrevivente de cada cabine \n",
    "        for index, row in todos[0:891].iterrows():  \n",
    "            if todos[0:891].iloc[index]['Cabin_2'] not in c_dict.keys():\n",
    "                c_dict[todos[0:891].iloc[index]['Cabin_2']] = [0,0]\n",
    "\n",
    "            s_ns = c_dict[todos[0:891].iloc[index]['Cabin_2']]\n",
    "\n",
    "            if todos[0:891].iloc[index]['Survived'] == 0:            \n",
    "                s_ns_novo = [s_ns[0] + 1, s_ns[1]]\n",
    "            elif todos[0:891].iloc[index]['Survived'] == 1: \n",
    "                s_ns_novo = [s_ns[0], s_ns[1] + 1]\n",
    "\n",
    "            c_dict[todos.iloc[index]['Cabin_2']] = s_ns_novo  \n",
    "\n",
    "        for index, row in todos.iterrows():  \n",
    "            if todos.iloc[index]['Cabin_2'] in c_dict:\n",
    "                todos.at[index, 'numero_sobrevivente_cabine'] =  c_dict[todos.iloc[index]['Cabin_2']][1] \n",
    "\n",
    "                todos.at[index, 'numero_total_cabine'] =  sum(c_dict[todos.iloc[index]['Cabin_2']] ) \n",
    "\n",
    "                if todos.iloc[index]['numero_total_cabine'] > 1:\n",
    "                    todos.at[index, 'relacao_s_ns_cabine'] = todos.iloc[index]['numero_sobrevivente_cabine']/todos.iloc[index]['numero_total_cabine']\n",
    "                else:\n",
    "                    todos.at[index, 'relacao_s_ns_cabine'] = var\n",
    "\n",
    "            if todos.iloc[index]['Cabin_2'] not in c_dict:\n",
    "                todos.at[index, 'numero_sobrevivente_cabine'] =  0.\n",
    "\n",
    "                todos.at[index, 'numero_total_cabine'] =  0.\n",
    "\n",
    "                todos.at[index, 'relacao_s_ns_cabine'] = var\n",
    "\n",
    "            if todos.iloc[index]['relacao_s_ns_cabine'] >= 0. and todos.iloc[index]['relacao_s_ns_cabine'] < 0.25:\n",
    "                todos.at[index, 'relacao_s_ns_cabine'] = 0.25\n",
    "            elif todos.iloc[index]['relacao_s_ns_cabine'] >= 0.25 and todos.iloc[index]['relacao_s_ns_cabine'] < 0.5:        \n",
    "                todos.at[index, 'relacao_s_ns_cabine'] = 0.5\n",
    "            elif todos.iloc[index]['relacao_s_ns_cabine'] >= 0.5 and todos.iloc[index]['relacao_s_ns_cabine'] < 0.75:        \n",
    "                todos.at[index, 'relacao_s_ns_cabine'] = 0.75      \n",
    "            elif todos.iloc[index]['relacao_s_ns_cabine'] >= 0.75:       \n",
    "                todos.at[index, 'relacao_s_ns_cabine'] = 1.0   \n",
    "\n",
    "        todos['Cabin_3'] =  todos['relacao_s_ns_cabine']        \n",
    "        todos = todos.infer_objects()\n",
    "        return todos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s = Sobrevivente_cabine()\n",
    "todos = s.transform(todos)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = ['Fare','Parch','SibSp', 'Age','Name_4','Cabin_3'] #\n",
    "cat_attribs = ['Pclass','Sex','Embarked']\n",
    "values_num = {'Fare': train['Fare'].median()}\n",
    "values_cat = {'Embarked' : 'X'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos, train_label  = Juntar_tratamento().transform(train, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformacao_pipeline = Pipeline([\n",
    "    ('Pronomes_tratamento', Pronomes_tratamento()),\n",
    "    ('Sobrevivente_familia', Sobrevivente_familia()),\n",
    "    ('Sobrevivente_cabine', Sobrevivente_cabine())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos = transformacao_pipeline.fit_transform(todos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos_filtrado = todos[['Fare','Parch','SibSp', 'Age','Name_4','Cabin_3','Pclass','Sex','Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('Preencher_vazios', Preencher_vazios(values_num)),\n",
    "        ('pd-np', DataFrameSelector(num_attribs)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "cat_pipeline = Pipeline([\n",
    "        ('Preencher_vazios', Preencher_vazios(values_cat)),\n",
    "        ('Transformar_categoricos',Transformar_categoricos()),\n",
    "        ('pd-np', DataFrameSelector(cat_attribs)),\n",
    "        ('OneHotEncoder',OneHotEncoder()),\n",
    "    ])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py:4355: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py:4355: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "cat_tr = full_pipeline.fit_transform(todos_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = cat_tr[0:891]\n",
    "train3 = cat_tr[891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8608305274971941\n",
      "Scores: [0.88888889 0.84444444 0.82022472 0.85393258 0.8988764  0.82022472\n",
      " 0.86516854 0.84269663 0.86516854 0.85227273]\n",
      "Mean: 0.855189819543752\n",
      "Standard deviation: 0.024433673757311536\n"
     ]
    }
   ],
   "source": [
    "#SGD######################################################################\n",
    "sgd_clf = SGDClassifier(max_iter=1000)\n",
    "sgd_clf.fit(train2, train_label)\n",
    "\n",
    "s = sgd_clf.predict(train2)\n",
    "print (accuracy_score(s, train_label))\n",
    "\n",
    "t = sgd_clf.predict(train3)\n",
    "t = zero_um(t)\n",
    "\n",
    "result_SGD = pd.concat([pd.DataFrame(data=t,columns =['Survived']),\n",
    "    test_set['PassengerId'].to_frame()],axis=1).set_index('PassengerId')\\\n",
    "    .astype('int64')\n",
    "\n",
    "#res2 = np.hstack([res2, np.array(result_SGD)])\n",
    "\n",
    "result_SGD.to_csv('SGD.csv')\n",
    "\n",
    "scores = cross_val_score(sgd_clf, train2, train_label,\n",
    "     scoring=\"accuracy\", cv=10)\n",
    "\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n",
      "Scores: [0.85555556 0.88888889 0.78651685 0.83146067 0.87640449 0.84269663\n",
      " 0.85393258 0.83146067 0.88764045 0.85227273]\n",
      "Mean: 0.8506829531267733\n",
      "Standard deviation: 0.02905862893780325\n"
     ]
    }
   ],
   "source": [
    "knn=neighbors.KNeighborsClassifier()\n",
    "knn.fit(train2, train_label)\n",
    "\n",
    "s = knn.predict(train2)\n",
    "print (accuracy_score(s, train_label))\n",
    "\n",
    "t = knn.predict(train3)\n",
    "result_knn = pd.concat([pd.DataFrame(data=t,columns =['Survived']),\n",
    "    test_set['PassengerId'].to_frame()],axis=1).set_index('PassengerId')\\\n",
    "    .astype('int64')\n",
    "#res2 = np.hstack([res2, np.array(result_knn)])\n",
    "result_knn.to_csv('knn.csv')\n",
    "\n",
    "scores = cross_val_score(knn, train2, train_label,\n",
    "     scoring=\"accuracy\", cv=10)\n",
    "\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8821548821548821\n",
      "Scores: [0.87777778 0.9        0.83146067 0.87640449 0.8988764  0.82022472\n",
      " 0.85393258 0.86516854 0.88764045 0.86363636]\n",
      "Mean: 0.8675122006582681\n",
      "Standard deviation: 0.025237890296031417\n"
     ]
    }
   ],
   "source": [
    "svwm=svm.SVC(C= 35938.0, gamma= 0.000562)\n",
    "#svwm=svm.SVC()\n",
    "svwm.fit(train2, train_label)\n",
    "\n",
    "s = svwm.predict(train2)\n",
    "print (accuracy_score(s, train_label))\n",
    "\n",
    "t = svwm.predict(train3)\n",
    "\n",
    "result_svn = pd.concat([pd.DataFrame(data=t,columns =['Survived']),\n",
    "    test_set['PassengerId'].to_frame()],axis=1).set_index('PassengerId')\\\n",
    "    .astype('int64')\n",
    "\n",
    "result_svn.to_csv('svn.csv')\n",
    "\n",
    "scores = cross_val_score(svwm, train2, train_label,\n",
    "     scoring=\"accuracy\", cv=10)\n",
    "\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9281705948372615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.88888889 0.9        0.82022472 0.8988764  0.95505618 0.83146067\n",
      " 0.91011236 0.86516854 0.86516854 0.875     ]\n",
      "Mean: 0.8809956304619225\n",
      "Standard deviation: 0.03709406599925418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1).fit(train2, train_label)\n",
    "\n",
    "s = gbm.predict(train2)\n",
    "\n",
    "print (accuracy_score(s, train_label))\n",
    "\n",
    "t = gbm.predict(train3)\n",
    "\n",
    "result_xgb = pd.concat([pd.DataFrame(data=t,columns =['Survived']),\n",
    "    test_set['PassengerId'].to_frame()],axis=1).set_index('PassengerId')\\\n",
    "    .astype('int64')\n",
    "    \n",
    "    \n",
    "#res2 = np.hstack([res2, np.array(result_xgb)])\n",
    "\n",
    "result_xgb.to_csv('xgb.csv')\n",
    "\n",
    "scores = cross_val_score(gbm, train2, train_label,\n",
    "     scoring=\"accuracy\", cv=10)\n",
    "\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9831649831649831\n"
     ]
    }
   ],
   "source": [
    "## RandomForestRegressor\n",
    "#forest_reg = RandomForestRegressor()\n",
    "forest_reg =RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "           min_impurity_split=None, min_samples_leaf=1,\n",
    "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "           n_estimators=700, n_jobs=1, oob_score=False, random_state=None,\n",
    "           verbose=0, warm_start=False)\n",
    "\n",
    "forest_reg.fit(train2, train_label)\n",
    "s = forest_reg.predict(train2)\n",
    "s = zero_um(s)\n",
    "print (accuracy_score(s, train_label))\n",
    "\n",
    "t = forest_reg.predict(train3)\n",
    "t = zero_um(t)\n",
    "\n",
    "result_random_forest = pd.concat([pd.DataFrame(data=t,columns =['Survived']),\n",
    "    test_set['PassengerId'].to_frame()],axis=1).set_index('PassengerId')\\\n",
    "    .astype('int64')\n",
    "\n",
    "result_random_forest.to_csv('random_forest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression()\n",
    "svm_clf = svm.SVC(C= 35938.0, gamma= 0.000562, probability=True)\n",
    "sgd_clf = SGDClassifier(max_iter=1000,loss='log')\n",
    "forest_reg =RandomForestRegressor()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "        estimators=[('lr', log_clf),('gbm',gbm), ('knn',knn), ('svc', svm_clf), ('sgd_dlf', sgd_clf)],\n",
    "        voting='soft'\n",
    "    )\n",
    "voting_clf.fit(train2, train_label)\n",
    "\n",
    "t = voting_clf.predict(train3)\n",
    "\n",
    "result_votes = pd.concat([pd.DataFrame(data=t,columns =['Survived']),\n",
    "    test_set['PassengerId'].to_frame()],axis=1).set_index('PassengerId')\\\n",
    "    .astype('int64')\n",
    "\n",
    "result_votes.to_csv('result_votes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8765432098765432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=3, n_estimators=3, learning_rate=1.0)\n",
    "gbrt.fit(train2, train_label)\n",
    "s = gbrt.predict(train2)\n",
    "s = zero_um(s)\n",
    "print (accuracy_score(s, train_label))\n",
    "\n",
    "t = gbrt.predict(train3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=1.0, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=3, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
